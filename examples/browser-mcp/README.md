# Browser Rendering MCP Server

A comprehensive Model Context Protocol (MCP) server that demonstrates Cloudflare Browser Rendering capabilities for web scraping, automation, and data extraction tasks.

## Features

### ğŸŒ Browser Automation Tools
- **navigate** - Navigate to URLs with customizable options (viewport, user agent, wait conditions)
- **screenshot** - Capture full page or element screenshots in multiple formats
- **extract_text** - Extract text content using CSS selectors or full page
- **extract_links** - Extract all links with filtering options (internal/external, text matching)
- **interact** - Perform browser interactions (click, fill forms, hover, scroll, evaluate JS)
- **wait_for** - Wait for elements, network idle, timeouts, or custom conditions
- **evaluate_js** - Execute custom JavaScript code in browser context
- **close_session** - Manage browser session lifecycle

### ğŸ“Š Session & Data Management
- **Browser Sessions** - Persistent browser sessions with metadata tracking
- **Page Cache** - R2-based caching of page content with TTL management
- **Extraction History** - D1 database storage of all scraping results
- **Extraction Patterns** - Reusable extraction patterns for different websites

### ğŸ¤– Intelligent Prompts
- **web_scraper** - Generate comprehensive scraping strategies for any website
- **automation_flow** - Create step-by-step browser automation workflows
- **data_extractor** - Design extraction patterns for structured data

### ğŸ“ˆ Monitoring & Analytics
- Real-time session monitoring and health checks
- Scraping statistics and performance metrics
- Automated cleanup of idle sessions and expired cache
- Comprehensive error handling and logging

## Quick Start

### 1. Installation

```bash
cd examples/browser-mcp
npm install
```

### 2. Configuration

Update `wrangler.jsonc` with your database and bucket IDs:

```jsonc
{
  "d1_databases": [
    {
      "binding": "DB",
      "database_name": "browser-mcp-db",
      "database_id": "your-database-id-here"
    }
  ],
  "r2_buckets": [
    {
      "binding": "CACHE_BUCKET",
      "bucket_name": "your-bucket-name"
    }
  ]
}
```

### 3. Database Setup

Create and migrate your D1 database:

```bash
# Create database
wrangler d1 create browser-mcp-db

# Run migrations (tables will be created automatically on first run)
wrangler d1 migrations apply browser-mcp-db --local
```

### 4. Development

```bash
# Start development server
npm run dev

# Or deploy to Cloudflare Workers
npm run deploy
```

## Usage Examples

### Basic Web Scraping

```javascript
// Navigate to a website
const navResult = await mcp.call("navigate", {
  url: "https://example.com",
  viewport: { width: 1280, height: 720 },
  waitUntil: "networkidle2"
});

// Extract structured data
const extractResult = await mcp.call("extract_text", {
  sessionId: navResult.sessionId,
  selectors: {
    title: "h1, .title",
    price: ".price, .cost",
    description: ".description, .summary"
  },
  multiple: true
});

// Take a screenshot for verification
const screenshot = await mcp.call("screenshot", {
  sessionId: navResult.sessionId,
  fullPage: true,
  format: "png"
});
```

### Form Automation

```javascript
// Navigate and interact with forms
const navResult = await mcp.call("navigate", {
  url: "https://example.com/contact",
  waitUntil: "domcontentloaded"
});

// Fill and submit form
const formResult = await mcp.call("interact", {
  sessionId: navResult.sessionId,
  actions: [
    { type: "fill", selector: "#name", value: "John Doe" },
    { type: "fill", selector: "#email", value: "john@example.com" },
    { type: "fill", selector: "#message", value: "Hello from MCP!" },
    { type: "click", selector: "#submit" }
  ],
  waitBetweenActions: 500
});

// Wait for confirmation
const confirmation = await mcp.call("wait_for", {
  sessionId: navResult.sessionId,
  condition: "element",
  selector: ".success, .confirmation",
  timeout: 10000
});
```

### Multi-Page Data Extraction

```javascript
async function extractAllPages(startUrl) {
  const allData = [];
  let currentPage = 1;
  let hasNextPage = true;
  
  // Initial navigation
  const navResult = await mcp.call("navigate", {
    url: startUrl,
    viewport: { width: 1280, height: 720 }
  });
  
  while (hasNextPage) {
    // Extract data from current page
    const pageData = await mcp.call("extract_text", {
      sessionId: navResult.sessionId,
      selectors: {
        items: ".product, .item, .result",
        titles: ".title, h2, h3",
        prices: ".price, .cost"
      },
      multiple: true
    });
    
    allData.push(...pageData.data);
    
    // Check for next page
    const nextPageExists = await mcp.call("evaluate_js", {
      sessionId: navResult.sessionId,
      code: "return !!document.querySelector('.next, .pagination .next')"
    });
    
    if (nextPageExists.result) {
      // Click next page
      await mcp.call("interact", {
        sessionId: navResult.sessionId,
        actions: [{ type: "click", selector: ".next, .pagination .next" }]
      });
      
      // Wait for new content
      await mcp.call("wait_for", {
        sessionId: navResult.sessionId,
        condition: "network",
        timeout: 10000
      });
      
      currentPage++;
    } else {
      hasNextPage = false;
    }
  }
  
  return allData;
}
```

### Using Intelligent Prompts

```javascript
// Generate a scraping strategy
const strategy = await mcp.call("web_scraper", {
  url: "https://news-site.com",
  data_requirements: "article headlines, publication dates, and author names",
  site_type: "news",
  complexity: "medium"
});

// Create an automation workflow
const workflow = await mcp.call("automation_flow", {
  task_description: "search for products and compare prices",
  starting_url: "https://shop.example.com",
  data_inputs: JSON.stringify({ searchTerm: "laptop" })
});

// Design extraction patterns
const patterns = await mcp.call("data_extractor", {
  url: "https://ecommerce.example.com/products",
  data_structure: "list of products with name, price, rating, and image",
  output_format: "json",
  pagination: "true"
});
```

## Resource Management

### Browser Sessions
Access session information:
- `browser://sessions` - List all sessions
- `browser://sessions/{sessionId}` - Get specific session details

### Scraping Results
View extraction history:
- `browser://results` - Recent scraping results and statistics
- `browser://results/{url}` - Results for specific URL

### Page Cache
Manage cached content:
- `browser://cache` - Cache statistics and management
- `browser://cache/{url}` - Cached content for specific URL

### Extraction Patterns
Reusable patterns:
- `browser://patterns` - All extraction patterns
- `browser://patterns/{domain}` - Patterns for specific domain

### System Status
Monitor health:
- `browser://status` - System health and configuration

## Configuration Options

### Environment Variables

```jsonc
{
  "vars": {
    "MAX_CONCURRENT_SESSIONS": "5",      // Maximum browser sessions
    "SESSION_TIMEOUT_MS": "300000",      // Session timeout (5 minutes)
    "CACHE_TTL_HOURS": "24",            // Cache time-to-live
    "MAX_PAGE_SIZE_MB": "10"            // Maximum cached page size
  }
}
```

### Browser Options
- **Viewport**: Customizable browser viewport size
- **User Agent**: Custom user agent strings
- **Wait Conditions**: Various wait strategies (load, networkidle, etc.)
- **Timeouts**: Configurable timeouts for all operations
- **Cookies**: Session cookie management

## API Endpoints

### Health & Status
- `GET /` - Service information and capabilities
- `GET /health` - Health check endpoint
- `GET /status` - Detailed status with metrics
- `POST /maintenance` - Trigger maintenance tasks

### MCP Protocol
- `POST /mcp` - Main MCP protocol endpoint
- `GET /mcp/ws` - WebSocket upgrade for MCP (if supported)

## Performance & Best Practices

### Session Management
- Reuse sessions when possible to avoid setup overhead
- Close sessions when done to free resources
- Monitor session limits and implement queuing if needed
- Use session timeouts to prevent resource leaks

### Caching Strategy
- Enable page caching for repeated visits
- Set appropriate TTL values for your use case
- Monitor cache size and implement cleanup
- Use selective caching for large pages

### Respectful Scraping
- Implement delays between requests
- Respect robots.txt and terms of service
- Use appropriate user agents
- Monitor and limit concurrent requests
- Implement exponential backoff for errors

### Error Handling
- Always use try/catch blocks
- Implement retry logic with backoff
- Capture screenshots on errors for debugging
- Log detailed error information
- Gracefully handle network timeouts

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Browser MCP Server            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tools: navigate, screenshot, extract,  â”‚
â”‚         interact, wait_for, evaluate    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Resources: sessions, results, cache,   â”‚
â”‚            patterns, status             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Prompts: web_scraper, automation_flow, â”‚
â”‚          data_extractor                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Browser Manager                  â”‚
â”‚    (Puppeteer + Session Management)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Repository Layer              â”‚
â”‚      (D1 Database + R2 Cache)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Cloudflare Workers Runtime       â”‚
â”‚   (Browser Rendering + D1 + R2)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Development

### Project Structure
```
src/
â”œâ”€â”€ index.ts           # Main Worker entry point
â”œâ”€â”€ server.ts          # MCP server implementation  
â”œâ”€â”€ browser-manager.ts # Browser session management
â”œâ”€â”€ repository.ts      # Data storage layer
â”œâ”€â”€ tools.ts           # MCP tools implementation
â”œâ”€â”€ resources.ts       # MCP resources
â”œâ”€â”€ prompts.ts         # Intelligent prompts
â””â”€â”€ schema.ts          # Data models and types
```

### Testing
```bash
# Run tests
npm test

# Run tests in watch mode
npm run test:watch

# Generate test coverage
npm run test:coverage
```

### Deployment
```bash
# Deploy to Cloudflare Workers
npm run deploy

# Deploy with specific environment
wrangler deploy --env production
```

## Troubleshooting

### Common Issues

**Session not found errors**:
- Sessions may timeout after inactivity
- Check session ID validity
- Implement session recreation logic

**Navigation timeouts**:
- Increase timeout values for slow sites
- Use appropriate wait conditions
- Check for JavaScript-heavy pages

**Extraction returns empty results**:
- Verify selectors are correct
- Wait for dynamic content to load
- Check for anti-bot measures

**Memory or resource limits**:
- Close unused sessions promptly
- Implement session pooling
- Monitor resource usage

### Debug Mode
Enable verbose logging by setting environment variables:
```bash
DEBUG=true wrangler dev
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## License

MIT License - see LICENSE file for details.

---

For more examples and advanced usage, check the `/test` directory and the MCP protocol documentation.
